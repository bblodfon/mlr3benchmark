% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/BenchmarkAggr.R
\name{BenchmarkAggr}
\alias{BenchmarkAggr}
\title{Aggregated Benchmark Result Object}
\description{
An R6 class for aggregated benchmark results.
}
\details{
An object of this class is not automatically generated by \link[mlr3:BenchmarkResult]{mlr3::BenchmarkResult},
instead it should either be constructed from the results of \verb{[mlr3::BenchmarkResult]$aggregate},
or custom data can be entered as long as this at least includes the column names \code{learner_id}
(for models) and \code{task_id} (for datasets). Direct coercions from \link[mlr3:BenchmarkResult]{mlr3::BenchmarkResult} are
available, which essentially wrap \verb{$aggregate.}
}
\examples{
library(mlr3)
task = tsks(c("boston_housing", "mtcars"))
learns = lrns(c("regr.featureless", "regr.rpart"))
bm = benchmark(benchmark_grid(task, learns, rsmp("cv", folds = 2)))

# direct coercion
# default measure
as.BenchmarkAggr(bm)
# custom measure
as.BenchmarkAggr(bm, msr("regr.rmse"))

# construct manually
BenchmarkAggr$new(bm$aggregate())

# construct from non-mlr object
df = data.frame(task_id = rep(c("A", "B"), each = 5),
                learner_id = paste0("L", 1:5),
                RMSE = runif(10))
BenchmarkAggr$new(df)
}
\references{
Janez Demsar, Statistical Comparisons of Classifiers over
Multiple Data Sets, JMLR, 2006
}
\section{Active bindings}{
\if{html}{\out{<div class="r6-active-bindings">}}
\describe{
\item{\code{data}}{\verb{([data.table::data.table])} \cr Aggregated data.}

\item{\code{learners}}{\code{(character())} \cr Unique learner names.}

\item{\code{tasks}}{\code{(character())} \cr Unique task names.}

\item{\code{measures}}{\code{(character())} \cr Unique measure names.}

\item{\code{nlrns}}{\code{(integers())} \cr Number of learners.}

\item{\code{ntasks}}{\code{(integers())} \cr Number of tasks.}

\item{\code{nmeas}}{\code{(integers())} \cr Number of measures.}

\item{\code{nrow}}{\code{(integers())} \cr Number of rows.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{BenchmarkAggr$new()}}
\item \href{#method-print}{\code{BenchmarkAggr$print()}}
\item \href{#method-rank_data}{\code{BenchmarkAggr$rank_data()}}
\item \href{#method-friedman_test}{\code{BenchmarkAggr$friedman_test()}}
\item \href{#method-friedman_posthoc}{\code{BenchmarkAggr$friedman_posthoc()}}
\item \href{#method-crit_differences}{\code{BenchmarkAggr$crit_differences()}}
\item \href{#method-clone}{\code{BenchmarkAggr$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Creates a new instance of this \link[R6:R6Class]{R6} class.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BenchmarkAggr$new(dt)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{dt}}{\code{(matrix(1))} \cr
\code{matrix} like object coercable to \link[=data.table]{data.table::data.table}, should
include column names "task_id" and "learner_id", coerced to factors internally,
and at least one measure (numeric).}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-print"></a>}}
\if{latex}{\out{\hypertarget{method-print}{}}}
\subsection{Method \code{print()}}{
Prints the internal data via \link[data.table:print.data.table]{data.table::print.data.table}.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BenchmarkAggr$print(...)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{...}}{Passed to \link[data.table:print.data.table]{data.table::print.data.table}.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-rank_data"></a>}}
\if{latex}{\out{\hypertarget{method-rank_data}{}}}
\subsection{Method \code{rank_data()}}{
Ranks the aggregated data given some measure.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BenchmarkAggr$rank_data(meas, minimize = TRUE, task = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{meas}}{\code{(character(1))} \cr
Measure to rank the data against, should be in \verb{$measures}. Can be \code{NULL} if only one measure
in data.}

\item{\code{minimize}}{\code{(logical(1))} \cr
Should the measure be minimized? Default is \code{TRUE}.}

\item{\code{task}}{\code{(character(1))} \cr
If \code{NULL} then returns a matrix of ranks where columns are tasks and rows are
learners, otherwise returns a one-column matrix of a specified task, should
be in \verb{$tasks}.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-friedman_test"></a>}}
\if{latex}{\out{\hypertarget{method-friedman_test}{}}}
\subsection{Method \code{friedman_test()}}{
Computes Friedman test over all tasks, assumes datasets are independent.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BenchmarkAggr$friedman_test(meas = NULL, p.adjust.method = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{meas}}{\code{(character(1))} \cr
Measure to rank the data against, should be in \verb{$measures}. If no measure is provided
then returns a matrix of tests for all measures.}

\item{\code{p.adjust.method}}{\code{(character(1))} \cr
Passed to \link{p.adjust} if \code{meas = NULL} for multiple testing correction. If \code{NULL}
then no correction applied.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-friedman_posthoc"></a>}}
\if{latex}{\out{\hypertarget{method-friedman_posthoc}{}}}
\subsection{Method \code{friedman_posthoc()}}{
Posthoc Friedman Nemenyi tests. Computed with
\link[PMCMR:posthoc.friedman.nemenyi.test]{PMCMR::posthoc.friedman.nemenyi.test}. If global \verb{$friedman_test} is non-significant then
this is returned and no post-hocs computed. Also returns critical difference
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BenchmarkAggr$friedman_posthoc(meas = NULL, p.value = 0.05)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{meas}}{\code{(character(1))} \cr
Measure to rank the data against, should be in \verb{$measures}. Can be \code{NULL} if only one measure
in data.}

\item{\code{p.value}}{\code{(numeric(1))} \cr
p.value for which the global test will be considered significant.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-crit_differences"></a>}}
\if{latex}{\out{\hypertarget{method-crit_differences}{}}}
\subsection{Method \code{crit_differences()}}{
Generate critical differences for a critical difference diagram.
Primarily should be used internally by \link{autoplot.BenchmarkAggr}.
FIXME - CONSIDER MOVING TO PRIVATE HELPER FUNCTION - PROBABLY NOT USEFUL IN ISOLATION
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BenchmarkAggr$crit_differences(
  meas = NULL,
  minimize = TRUE,
  p.value = 0.05,
  baseline = NULL,
  test = c("bd", "nemenyi")
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{meas}}{\code{(character(1))} \cr
Measure to rank the data against, should be in \verb{$measures}. Can be \code{NULL} if only one measure
in data.}

\item{\code{minimize}}{\code{(logical(1))} \cr
Should the measure be minimized? Default is \code{TRUE}.}

\item{\code{p.value}}{\code{(numeric(1))} \cr
p.value for which the global test will be considered significant.}

\item{\code{baseline}}{\code{(character(1))} \cr
For \code{test = "bd"} a baseline learner to compare the other learners to,
should be in \verb{$learners}.}

\item{\code{test}}{(\verb{character(1))}) \cr
Should critical differences be computed from Bonferroni-Dunn (\code{bd}) or
Nemenyi (\code{nemenyi}) tests? Default is Bonferroni-Dunn.}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
Copied from mlr:
Bonferroni-Dunn usually yields higher power than Nemenyi as it does not
compare all algorithms to each other, but all algorithms to a
\code{baseline} instead.
Critical differences calculated as:
\deqn{CD = q_{\alpha} \sqrt{\left(\frac{k(k+1)}{6N}\right)}}{CD = q_alpha sqrt(k(k+1)/(6N))} \cr # nolint
Where \eqn{q_\alpha} is based on the studentized range statistic.
See references for details.
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BenchmarkAggr$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
